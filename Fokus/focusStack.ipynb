{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FocusStack\n",
    "from glob import glob\n",
    "from os.path import basename\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilder = glob('../../bilderserien/TPKarton/F*/camera04.jpg')\n",
    "bilderDict: dict[str, list] = {}\n",
    "for b in bilder:\n",
    "    n = basename(b)\n",
    "    if n not in bilderDict:\n",
    "        bilderDict[n] = []\n",
    "    bilderDict[n].append(cv2.imread(b))\n",
    "images = bilderDict['camera04.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findHomography(image_1_kp, image_2_kp, matches):\n",
    "    image_1_points = np.zeros((len(matches), 1, 2), dtype=np.float32)\n",
    "    image_2_points = np.zeros((len(matches), 1, 2), dtype=np.float32)\n",
    "    for i in range(0, len(matches)):\n",
    "        image_1_points[i] = image_1_kp[matches[i].queryIdx].pt\n",
    "        image_2_points[i] = image_2_kp[matches[i].trainIdx].pt\n",
    "    homography, mask = cv2.findHomography(\n",
    "        image_1_points, image_2_points, cv2.RANSAC, ransacReprojThreshold=2.0)\n",
    "    return homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "[[ 9.97317829e-01 -6.32937159e-04  7.94036481e+00]\n",
      " [ 3.38095344e-04  9.95854551e-01  5.56122848e+00]\n",
      " [ 2.97922399e-07 -2.65088026e-07  1.00000000e+00]]\n",
      "Aligning image 2\n",
      "[[ 9.82039084e-01 -3.98119500e-03  4.70981264e+01]\n",
      " [ 1.15171300e-03  9.72764470e-01  3.08505587e+01]\n",
      " [ 1.18550462e-06 -2.47418640e-06  1.00000000e+00]]\n",
      "Aligning image 3\n",
      "[[ 9.71762183e-01  9.33341268e-04  6.88607696e+01]\n",
      " [ 1.44605095e-03  9.59129863e-01  4.87045817e+01]\n",
      " [ 1.18294102e-06 -9.15289304e-07  1.00000000e+00]]\n",
      "Aligning image 4\n",
      "[[9.74443981e-01 2.60323630e-03 6.01448402e+01]\n",
      " [3.24399286e-04 9.74096265e-01 3.48434163e+01]\n",
      " [2.36550360e-07 9.91366661e-07 1.00000000e+00]]\n",
      "Aligning image 5\n",
      "[[ 9.32804649e-01 -7.75767449e-04  1.30657374e+02]\n",
      " [-7.30215097e-03  9.40267950e-01  7.90722699e+01]\n",
      " [-4.43913948e-06 -1.04377364e-06  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#   SIFT generally produces better results, but it is not FOSS, so chose the feature detector\n",
    "#   that suits the needs of your project.  ORB does OK\n",
    "use_sift = True\n",
    "\n",
    "outimages = []\n",
    "\n",
    "if use_sift:\n",
    "    detector = cv2.xfeatures2d.SIFT_create()\n",
    "else:\n",
    "    detector = cv2.ORB_create(1000)\n",
    "\n",
    "#   We assume that image 0 is the \"base\" image and align everything to it\n",
    "print(\"Detecting features of base image\")\n",
    "outimages.append(images[0])\n",
    "image1gray = cv2.cvtColor(images[0], cv2.COLOR_BGR2GRAY)\n",
    "image_1_kp, image_1_desc = detector.detectAndCompute(image1gray, None)\n",
    "\n",
    "for i in range(1, len(images)):\n",
    "    print(\"Aligning image {}\".format(i))\n",
    "    image_i_kp, image_i_desc = detector.detectAndCompute(images[i], None)\n",
    "\n",
    "    if use_sift:\n",
    "        bf = cv2.BFMatcher()\n",
    "        # This returns the top two matches for each feature point (list of list)\n",
    "        pairMatches = bf.knnMatch(image_i_desc, image_1_desc, k=2)\n",
    "        rawMatches = []\n",
    "        for m, n in pairMatches:\n",
    "            if m.distance < 0.7*n.distance:\n",
    "                rawMatches.append(m)\n",
    "    else:\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "        rawMatches = bf.match(image_i_desc, image_1_desc)\n",
    "\n",
    "    sortMatches = sorted(rawMatches, key=lambda x: x.distance)\n",
    "    matches = sortMatches[0:128]\n",
    "\n",
    "    hom = findHomography(image_i_kp, image_1_kp, matches)\n",
    "    print(hom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting features of base image\n",
    "Aligning image 1\n",
    "[[ 9.85134338e-01 -1.94441602e-03  3.09039706e+01]\n",
    " [-7.46280738e-04  9.86053622e-01  1.86755548e+01]\n",
    " [-6.55692138e-07 -4.01536734e-07  1.00000000e+00]]\n",
    "Aligning image 2\n",
    "[[ 9.73494911e-01 -1.78204697e-03  5.53319679e+01]\n",
    " [-1.68667652e-03  9.76122090e-01  3.04705512e+01]\n",
    " [-1.30117625e-06 -1.43300602e-07  1.00000000e+00]]\n",
    "Aligning image 3\n",
    "[[ 9.70064949e-01 -3.20645210e-03  8.33205248e+01]\n",
    " [ 2.53368857e-03  9.63822237e-01  4.46591145e+01]\n",
    " [ 2.45135919e-06 -1.43876694e-06  1.00000000e+00]]\n",
    "Aligning image 4\n",
    "[[ 9.67711750e-01  3.94349359e-03  6.96564954e+01]\n",
    " [-1.73342747e-03  9.73736433e-01  3.71827876e+01]\n",
    " [-1.28694921e-06  2.17531778e-06  1.00000000e+00]]\n",
    "Aligning image 5\n",
    "[[ 9.50880158e-01 -2.13785905e-03  1.13850532e+02]\n",
    " [ 6.32479163e-04  9.51894191e-01  5.78017502e+01]\n",
    " [ 8.98913831e-08 -1.10454699e-06  1.00000000e+00]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@103.424] global shadow_sift.hpp:13 SIFT_create DEPRECATED: cv.xfeatures2d.SIFT_create() is deprecated due SIFT tranfer to the main repository. https://github.com/opencv/opencv/issues/16736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n",
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n",
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n",
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n",
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n",
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n",
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n",
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n",
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n",
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n",
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n",
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n",
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n",
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n",
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n",
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n",
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n",
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n",
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n",
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n",
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n",
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n",
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n",
      "Detecting features of base image\n",
      "Aligning image 1\n",
      "Aligning image 2\n",
      "Computing the laplacian of the blurred images\n",
      "Lap 0\n",
      "Lap 1\n",
      "Lap 2\n",
      "Shape of array of laplacians = (3, 2592, 4608)\n"
     ]
    }
   ],
   "source": [
    "for bild in bilderDict:\n",
    "    merged = FocusStack.focus_stack(bilderDict[bild])\n",
    "    cv2.imwrite(f'../../bilderserien/Moai/SF30-60/{bild}', merged)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
